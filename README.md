# Let me introduce myself

>##目录
>
>[TOC]

## scrapBaiduPics.py

scrapBaiduPics.py 根据关键字抓取**百度图片**，对抓取图片的数量没有限制，相对 scrapBaiduPics2000.py，scrapBaiduPics.py 速度较慢。

>**输入**
>
>> 根据提示`Input key word: `输入要检索图片的关键字，如`小黄人 `；
>>
>> 由提示`Input page: `，输入要下载图片的页数，如`20 `；
>>
>> 提示：一页有60张图片，最终下载的图片共`1200=20*60 `张。
>
>**输出**
>>下载的图片保存在以关键字命名的文件夹中，文件夹和运行的代码同目录

## scrapBaiduPics2000.py

scrapBaiduPics2000.py 根据关键字抓取**百度图片**。

**提示**：由于百度图片API限制了下载图片的数量，本脚本至多抓取2000张百度图片。

>**输入**
>
>> 根据提示`Input keyword: `输入要检索图片的关键字，如`小黄人 `；
>>
>> 由提示`Input the number of request pictures : `，输入要下载图片的数量数，如`20 `；
>>
>> 若不输入图片数量，默认下载2000张图片。
>
>**输出**
>>下载的图片保存在以**关键字**命名的文件夹中，文件夹和运行的代码同目录

## getbaidunews.py

getbaidunews.py根据关键字抓取**百度新闻**，并利用jieda分词工具获得新闻内容和新闻标题中的**地址**信息。

**提示**：由于百度新闻搜索引擎至多显示720条新闻，本脚本至多抓取720条百度新闻。


>**操作说明**
>
>> 根据要检索的关键字，修改变量`query_word`，如搜索`红火蚁`，则修改代码`query_word = '红火蚁'`
>
>**输出**
>>所有信息保存在**result.csv**，内容如下：
>>
>>>发布日期
>>>
>>>新闻内容分词结果
>>>
>>>新闻内容
>>>
>>>地址
>>>
>>>链接
>>>
>>>来源
>>>
>>>标题
>>>
>>>新闻标题分词结果
